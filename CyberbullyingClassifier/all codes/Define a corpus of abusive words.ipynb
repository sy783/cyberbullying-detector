{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f3d7c02",
   "metadata": {},
   "source": [
    "## Cyberbullying Detection: A Machine Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd \n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2e369",
   "metadata": {},
   "source": [
    "### Step 1: Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cyberbullying_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeae2e3",
   "metadata": {},
   "source": [
    "### Step 2 : Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert uppercase to lowercase characters\n",
    "def lower_word(t):\n",
    "    new_text = \"\".join(t.lower())\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove usernames, url and non utf8/ascii characters \n",
    "def rem_url(t):\n",
    "    text1 = \"\".join(re.sub(r'(?:\\@|https?\\://)\\S+', '', t))\n",
    "    text = \"\".join(re.sub(r'[^\\x00-\\x7f]',r'', text1))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove punctuation \n",
    "def rem_punc(t):\n",
    "        new_text = \"\".join(re.sub(r'[^\\w\\s]', '', t))\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac15911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to break the sentence into tokens\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def create_token(t):\n",
    "        token_text = \" \".join(word_tokenize(t))\n",
    "        return token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693edb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split strings into list and join as string \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('not')\n",
    "stop_words.extend(['rt', 'mkr', 'httpâ', 'tvwâ', 'etc'])\n",
    "\n",
    "def rem_stopword(t):\n",
    "    new_text = \" \".join([word for word in t.split() if word not in stop_words])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDNET LEMMATIZER (with appropriate pos tags)\n",
    "from nltk.stem import wordnet \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def lemma_postag(t):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to lemmatize each word with its POS tag\n",
    "\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # tokenize the sentence and find the POS tag for each token\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "\n",
    "    # our own pos_tagger function to make things simpler to understand.\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            # else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "\n",
    "    return lemmatized_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b41b2",
   "metadata": {},
   "source": [
    "### Step 3: Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e302276",
   "metadata": {},
   "source": [
    "#### To label the data into their respective categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing TextBlob with VADER\n",
    "from textblob import TextBlob\n",
    "\n",
    "#TextBlob\n",
    "def getPolarity_TB(t):\n",
    "    result = TextBlob(t).sentiment.polarity\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(polarity):\n",
    "    if polarity < 0:\n",
    "        return 'Negative'\n",
    "    elif polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cbd9c",
   "metadata": {},
   "source": [
    "#### Test find abusive words in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data\n",
    "def cleanData(x):\n",
    "    lower = lower_word(x)\n",
    "    no_url = rem_url(lower)\n",
    "    no_punc = rem_punc(no_url)\n",
    "    token = create_token(no_punc)\n",
    "    no_sw = rem_stopword(token)\n",
    "    new_text = lemma_postag(no_sw)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2f8d2",
   "metadata": {},
   "source": [
    "#### Test on actual data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData2 = pd.DataFrame(df['tweet_text'])\n",
    "\n",
    "testData2['clean'] = testData2['tweet_text'].apply(lambda x: cleanData(x))\n",
    "testData2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb68e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData2['tokenized'] = testData2['clean'].apply(lambda x: word_tokenize(x))\n",
    "testData2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData2['tokenized'].to_csv(\"tokenized_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "abusiveWords2 = [] #create a list\n",
    "positiveWords2 = []\n",
    "neutralWords2 = []\n",
    "i = len(testData2['tokenized'])\n",
    "j = 0\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        #print(x)\n",
    "        word = x\n",
    "        polarity = getPolarity_TB(word)\n",
    "        #print('Word: {}   Polarity: {}'.format(word, polarity))\n",
    "        if polarity <= 0.0:\n",
    "            abusiveWords2.append(word)\n",
    "        elif polarity == 0.0:\n",
    "            neutralWords2.append(word)\n",
    "        else:\n",
    "            positiveWords2.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in abusiveWords2 \n",
    "\n",
    "final_abusiveWords2 = list(dict.fromkeys(abusiveWords2))\n",
    "print(final_abusiveWords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords2))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a62562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "with open(r'abusiveWordsTEXTBLOB.txt', 'w') as filePath:\n",
    "    for a in final_abusiveWords2:\n",
    "        filePath.write(\"%s\\n\" % a)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in positiveWords2\n",
    "\n",
    "final_positiveWords2 = list(dict.fromkeys(positiveWords2))\n",
    "print(final_positiveWords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of positive words:\", len(positiveWords2))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_positiveWords2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdf022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all positive words into a txt file\n",
    "with open(r'positiveWordsTEXTBLOB.txt', 'w') as filePath:\n",
    "    for a in final_positiveWords2:\n",
    "        filePath.write(\"%s\\n\" % a)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in neutralWords2\n",
    "\n",
    "final_neutralWords2 = list(dict.fromkeys(neutralWords2))\n",
    "print(final_neutralWords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of neutral words:\", len(neutralWords2))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_neutralWords2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all neutral words into a txt file\n",
    "with open(r'neutralWordsTEXTBLOB.txt', 'w') as filePath:\n",
    "    for a in final_neutralWords2:\n",
    "        filePath.write(\"%s\\n\" % a)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc15bd4",
   "metadata": {},
   "source": [
    "#### Try using VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c0b12",
   "metadata": {},
   "source": [
    "Since it will take a very long time to process all the rows in one go, so it will be separated 5 different range starting from (1 - 10000), (10001 - 20000), (20001 - 30000), (30001 - 40000), (40001 - 47692). In this process, the words of each line will be categorized into their own categories. It has 3 categories which are abusive words, positive words, and neutral words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def getCompound(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    result = sentiment_dict['compound']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "\n",
    "abusiveWords4 = [] #create a list that contains all words that have negative meaning\n",
    "positiveWords4 = []\n",
    "neutralWords4 = []\n",
    "i = len(testData2['tokenized'][1:10000])\n",
    "j = 0\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        #print(x)\n",
    "        word = x\n",
    "        polarity = getCompound(word)\n",
    "        #print('Word: {}   Polarity: {}'.format(word, polarity))\n",
    "        if polarity >= 0.05:\n",
    "            positiveWords4.append(word)\n",
    "        elif polarity <= - 0.05:\n",
    "            abusiveWords4.append(word)\n",
    "        else:\n",
    "            neutralWords4.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in abusiveWords4\n",
    "\n",
    "final_abusiveWords4 = list(dict.fromkeys(abusiveWords4))\n",
    "print(final_abusiveWords4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a3663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the length of original abusive words list and the length of new abusive words list\n",
    "\n",
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords4))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "\n",
    "with open(r'abusiveWordsVADER1.txt', 'w') as fp:\n",
    "    for item in final_abusiveWords4:\n",
    "        fp.write(\"%s\\n\" % item) #write each word in new line\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in positiveWords4 \n",
    "\n",
    "final_positiveWords4 = list(dict.fromkeys(positiveWords4))\n",
    "print(final_positiveWords4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d36c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of positive words:\", len(positiveWords4))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_positiveWords4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all positive words into a txt file\n",
    "\n",
    "with open(r'positiveWordsVADER1.txt', 'w') as fp:\n",
    "    for item in final_positiveWords4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words in neutralWords4\n",
    "\n",
    "final_neutralWords4 = list(dict.fromkeys(neutralWords4))\n",
    "print(final_neutralWords4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80d8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of neutral words:\", len(neutralWords4))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_neutralWords4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba543d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all neutral words into a txt file\n",
    "with open(r'neutralWordsVADER1.txt', 'w') as fp:\n",
    "    for item in final_neutralWords4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c81d14",
   "metadata": {},
   "source": [
    "#### 10001 - 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "abusiveWords5 = [] #create a list\n",
    "positiveWords5 = []\n",
    "neutralWords5 = []\n",
    "i = len(testData2['tokenized'][10001:20000])\n",
    "j = 10001\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        word = x\n",
    "        polarity = getCompound(word)\n",
    "        if polarity >= 0.05:\n",
    "            positiveWords5.append(word)\n",
    "        elif polarity <= - 0.05:\n",
    "            abusiveWords5.append(word)\n",
    "        else:\n",
    "            neutralWords5.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87650af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testData2['tokenized'][10001:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9831d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words\n",
    "\n",
    "final_abusiveWords5 = list(dict.fromkeys(abusiveWords5))\n",
    "print(final_abusiveWords5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e836d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords5))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "with open(r'abusiveWordsVADER2.txt', 'w') as fp:\n",
    "    for item in final_abusiveWords5:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dcef8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### 20001 - 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9742330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "abusiveWords6 = [] #create a list\n",
    "positiveWords6 = []\n",
    "neutralWords6 = []\n",
    "i = len(testData2['tokenized'][20001:30000])\n",
    "j = 20001\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        #print(x)\n",
    "        word = x\n",
    "        polarity = getCompound(word)\n",
    "        #print('Word: {}   Polarity: {}'.format(word, polarity))\n",
    "        if polarity >= 0.05:\n",
    "            positiveWords6.append(word)\n",
    "        elif polarity <= - 0.05:\n",
    "            abusiveWords6.append(word)\n",
    "        else:\n",
    "            neutralWords6.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eba323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words\n",
    "\n",
    "final_abusiveWords6 = list(dict.fromkeys(abusiveWords6))\n",
    "print(final_abusiveWords6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords6))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2804378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "with open(r'abusiveWordsVADER3.txt', 'w') as fp:\n",
    "    for item in final_abusiveWords6:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304681b0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### 30001 - 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "abusiveWords7 = [] #create a list\n",
    "positiveWords7 = []\n",
    "neutralWords7 = []\n",
    "i = len(testData2['tokenized'][30001:40000])\n",
    "j = 30001\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        #print(x)\n",
    "        word = x\n",
    "        polarity = getCompound(word)\n",
    "        #print('Word: {}   Polarity: {}'.format(word, polarity))\n",
    "        if polarity >= 0.05:\n",
    "            positiveWords7.append(word)\n",
    "        elif polarity <= - 0.05:\n",
    "            abusiveWords7.append(word)\n",
    "        else:\n",
    "            neutralWords7.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b818b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words\n",
    "\n",
    "final_abusiveWords7 = list(dict.fromkeys(abusiveWords7))\n",
    "print(final_abusiveWords7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23128973",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords7))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "with open(r'abusiveWordsVADER4.txt', 'w') as fp:\n",
    "    for item in final_abusiveWords7:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91817aeb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### 40001 - 47692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the polarity of each word and put it in a list\n",
    "abusiveWords8 = [] #create a list\n",
    "positiveWords8 = []\n",
    "neutralWords8 = []\n",
    "i = len(testData2['tokenized'][40001:])\n",
    "j = 40001\n",
    "    \n",
    "while i != 0:\n",
    "    for x in testData2['tokenized'][j]:\n",
    "        #print(x)\n",
    "        word = x\n",
    "        polarity = getCompound(word)\n",
    "        #print('Word: {}   Polarity: {}'.format(word, polarity))\n",
    "        if polarity >= 0.05:\n",
    "            positiveWords8.append(word)\n",
    "        elif polarity <= - 0.05:\n",
    "            abusiveWords8.append(word)\n",
    "        else:\n",
    "            neutralWords8.append(word)\n",
    "    i = i - 1\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicated words\n",
    "\n",
    "final_abusiveWords8 = list(dict.fromkeys(abusiveWords8))\n",
    "print(final_abusiveWords8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The length of the orginal list of abusive words:\", len(abusiveWords8))\n",
    "print(\"After removing the duplicated words, this is the length of the new list:\", len(final_abusiveWords8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy all abusive words into a txt file\n",
    "with open(r'abusiveWordsVADER5.txt', 'w') as fp:\n",
    "    for item in final_abusiveWords8:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac591d4",
   "metadata": {},
   "source": [
    "#### Combine all 5 abusive text file into one "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751411f",
   "metadata": {},
   "source": [
    "Copied the all words into a textfile called \"abusiveWordsVADER-full\" then used excel to remove the duplicated values. After removing the duplicates, will check that if it is a abusive word then convert it back to a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9318011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abandon\\r\\nabandonment\\r\\nabduction\\r\\nabhor\\r\\nabhorrent\\r\\nabhors\\r\\nabuse\\r\\nabused\\r\\nabuser\\r\\nabusing\\r\\nabusive\\r\\naccident\\r\\naccidental\\r\\naccidentally\\r\\naccusation\\r\\naccuse\\r\\naccuses\\r\\nache\\r\\nadversary\\r\\nadverse\\r\\nadversity\\r\\naffected\\r\\naggravate\\r\\naggravating\\r\\naggression\\r\\naggressive\\r\\naggressively\\r\\naggressor\\r\\nagitate\\r\\nagitation\\r\\nagitator\\r\\nagony\\r\\nalarm\\r\\nallergic\\r\\nalone\\r\\namoral\\r\\nanger\\r\\nangered\\r\\nangrier\\r\\nangrily\\r\\nangry\\r\\nanimosity\\r\\nannoy\\r\\nannoyance\\r\\nannoyed\\r\\nannoying\\r\\nannoys\\r\\nantagonism\\r\\nantagonist\\r\\nantagonize\\r\\nanti\\r\\nanxiety\\r\\nanxious\\r\\napathy\\r\\napeshit\\r\\napocalyptic\\r\\napologizing\\r\\nappalled\\r\\nappalling\\r\\nappallingly\\r\\narguably\\r\\nargue\\r\\nargues\\r\\narguing\\r\\nargument\\r\\nargumentative\\r\\narrest\\r\\narrogance\\r\\narrogant\\r\\nashamed\\r\\nass\\r\\nassassination\\r\\nassault\\r\\nassaulted\\r\\nassaults\\r\\nassholes\\r\\nattack\\r\\nattacked\\r\\nattacker\\r\\nattacking\\r\\nattacks\\r\\naversion\\r\\navert\\r\\navoid\\r\\navoided\\r\\navoiders\\r\\navoids\\r\\nawful\\r\\nawkward\\r\\nawkwardly\\r\\nawkwardness\\r\\naxe\\r\\naxed\\r\\nbad\\r\\nbadly\\r\\nbailout\\r\\nbamboozle\\r\\nban\\r\\nbanish\\r\\nbarrier\\r\\nbastard\\r\\nbastardise\\r\\nbattle\\r\\nbeaten\\r\\nbeating\\r\\nbelittle\\r\\nbereave\\r\\nbetray\\r\\nbetrayal\\r\\nbetrayed\\r\\nbetrays\\r\\nbias\\r\\nbiased\\r\\nbitch\\r\\nbitchery\\r\\nbitches\\r\\nbitching\\r\\nbitchy\\r\\nbitter\\r\\nbitterness\\r\\nbittersweet\\r\\nbizarre\\r\\nblah\\r\\nblame\\r\\nblamed\\r\\nblames\\r\\nblaming\\r\\nblind\\r\\nblock\\r\\nblocked\\r\\nbloody\\r\\nblurry\\r\\nbomb\\r\\nbore\\r\\nbored\\r\\nboredom\\r\\nboring\\r\\nbother\\r\\nbothered\\r\\nbothersome\\r\\nboycott\\r\\nboycotting\\r\\nbribe\\r\\nbroke\\r\\nbroken\\r\\nbrutal\\r\\nbrutality\\r\\nbrutalize\\r\\nbrutally\\r\\nbullied\\r\\nbullshit\\r\\nbully\\r\\nbullying\\r\\nbummer\\r\\nburden\\r\\ncancel\\r\\ncancelled\\r\\ncancelling\\r\\ncancer\\r\\ncareless\\r\\ncarelessly\\r\\ncasualty\\r\\ncautious\\r\\ncensor\\r\\nchallenged\\r\\nchaos\\r\\nchaotic\\r\\nchastise\\r\\ncheat\\r\\ncheated\\r\\ncheater\\r\\ncheating\\r\\nchildish\\r\\nchoke\\r\\nclueless\\r\\ncock\\r\\ncocksucker\\r\\ncocky\\r\\ncollapse\\r\\ncollapsed\\r\\ncombat\\r\\ncomplacent\\r\\ncomplain\\r\\ncomplainer\\r\\ncomplaining\\r\\ncomplains\\r\\ncomplaint\\r\\ncondemn\\r\\ncondemnation\\r\\ncondemned\\r\\ncondemns\\r\\nconflict\\r\\nconfront\\r\\nconfrontation\\r\\nconfrontational\\r\\nconfronting\\r\\nconfronts\\r\\nconfuse\\r\\nconfused\\r\\nconfuses\\r\\nconfusion\\r\\nconspiracy\\r\\ncontagious\\r\\ncontempt\\r\\ncontemptible\\r\\ncontemptuously\\r\\ncontradict\\r\\ncontradiction\\r\\ncontradictory\\r\\ncontradicts\\r\\ncontroversial\\r\\ncorpse\\r\\ncoward\\r\\ncowardly\\r\\ncramp\\r\\ncrap\\r\\ncrappy\\r\\ncrash\\r\\ncraze\\r\\ncrazed\\r\\ncraziest\\r\\ncrazy\\r\\ncried\\r\\ncrime\\r\\ncriminal\\r\\ncrisis\\r\\ncritic\\r\\ncritical\\r\\ncriticise\\r\\ncriticism\\r\\ncriticize\\r\\ncriticizing\\r\\ncrude\\r\\ncrudely\\r\\ncruel\\r\\ncruelly\\r\\ncruelty\\r\\ncrush\\r\\ncry\\r\\ncunt\\r\\ncurse\\r\\ncut\\r\\ncutting\\r\\ncynic\\r\\ndamage\\r\\ndamaging\\r\\ndamn\\r\\ndamnation\\r\\ndamned\\r\\ndamnit\\r\\ndanger\\r\\ndangerous\\r\\ndangerously\\r\\ndarkest\\r\\ndarkness\\r\\ndaze\\r\\ndead\\r\\ndeafening\\r\\ndeath\\r\\ndebt\\r\\ndeceit\\r\\ndeceive\\r\\ndeception\\r\\ndefeat\\r\\ndefeated\\r\\ndefect\\r\\ndefective\\r\\ndefensively\\r\\ndefer\\r\\ndefiant\\r\\ndeficit\\r\\ndegradation\\r\\ndegrade\\r\\ndegraded\\r\\ndegrading\\r\\ndehumanize\\r\\ndehumanized\\r\\ndehumanizes\\r\\ndeject\\r\\ndelay\\r\\ndelayed\\r\\ndemand\\r\\ndenied\\r\\ndenier\\r\\ndenies\\r\\ndenounce\\r\\ndeny\\r\\ndenying\\r\\ndepress\\r\\ndepressant\\r\\ndepressed\\r\\ndepressing\\r\\ndepressingly\\r\\ndepression\\r\\ndeprive\\r\\ndeprives\\r\\nderail\\r\\nderide\\r\\ndespair\\r\\ndesperate\\r\\ndesperately\\r\\ndesperation\\r\\ndespise\\r\\ndespised\\r\\ndestroy\\r\\ndestroyed\\r\\ndestroyer\\r\\ndestroys\\r\\ndestructed\\r\\ndestruction\\r\\ndestructive\\r\\ndetain\\r\\ndevastate\\r\\ndevastating\\r\\ndevil\\r\\ndevilish\\r\\ndevils\\r\\ndick\\r\\ndickhead\\r\\ndie\\r\\ndied\\r\\ndifficult\\r\\ndifficulty\\r\\ndilemma\\r\\ndipshit\\r\\ndire\\r\\ndirt\\r\\ndirtier\\r\\ndirty\\r\\ndisadvantage\\r\\ndisadvantaged\\r\\ndisagree\\r\\ndisagreed\\r\\ndisagreement\\r\\ndisagrees\\r\\ndisappear\\r\\ndisappoint\\r\\ndisappointed\\r\\ndisappointing\\r\\ndisappointment\\r\\ndisappoints\\r\\ndisaster\\r\\ndiscard\\r\\ndiscomfort\\r\\ndiscord\\r\\ndiscourage\\r\\ndiscouraged\\r\\ndisdain\\r\\ndisgrace\\r\\ndisguise\\r\\ndisgust\\r\\ndisgusted\\r\\ndisgusting\\r\\ndisgustingly\\r\\ndishearten\\r\\ndishonest\\r\\ndisillusion\\r\\ndislike\\r\\ndisliked\\r\\ndisliking\\r\\ndismal\\r\\ndismay\\r\\ndisorder\\r\\ndisparage\\r\\ndispute\\r\\ndisqualified\\r\\ndisregard\\r\\ndisrespect\\r\\ndisruption\\r\\ndisruptive\\r\\ndistort\\r\\ndistract\\r\\ndistraction\\r\\ndistress\\r\\ndisturb\\r\\ndisturbed\\r\\ndisturber\\r\\ndizzy\\r\\ndodgy\\r\\ndominate\\r\\ndomination\\r\\ndoom\\r\\ndork\\r\\ndorkiest\\r\\ndorks\\r\\ndoubt\\r\\ndoubtful\\r\\ndouche\\r\\ndouchebag\\r\\ndownside\\r\\ndrag\\r\\ndragged\\r\\ndread\\r\\ndreadful\\r\\ndreading\\r\\ndreadlock\\r\\ndroopy\\r\\ndrop\\r\\ndrown\\r\\ndrunk\\r\\ndubious\\r\\ndud\\r\\ndull\\r\\ndullard\\r\\ndumb\\r\\ndumbass\\r\\ndumbbell\\r\\ndumber\\r\\ndumbest\\r\\ndumbing\\r\\ndumbs\\r\\ndump\\r\\ndumped\\r\\ndumpster\\r\\ndumpy\\r\\ndupe\\r\\negotistical\\r\\negotistically\\r\\nembarrass\\r\\nembarrassed\\r\\nembarrassing\\r\\nembarrassment\\r\\nembittered\\r\\nemergency\\r\\nemptiness\\r\\nempty\\r\\nenemies\\r\\nenemy\\r\\nenrage\\r\\nenrages\\r\\nenslave\\r\\nenslaved\\r\\nenslaves\\r\\nenvious\\r\\nenvy\\r\\nerroneous\\r\\nerror\\r\\neviction\\r\\nevil\\r\\nexaggerate\\r\\nexaggerated\\r\\nexclude\\r\\nexclusion\\r\\nexcruciatingly\\r\\nexhaust\\r\\nexhausted\\r\\nexhausting\\r\\nexhaustion\\r\\nexpel\\r\\nexploit\\r\\nexpose\\r\\nexposed\\r\\nfag\\r\\nfaggot\\r\\nfail\\r\\nfailed\\r\\nfailing\\r\\nfails\\r\\nfailure\\r\\nfaithless\\r\\nfake\\r\\nfalsify\\r\\nfarce\\r\\nfascist\\r\\nfascists\\r\\nfatal\\r\\nfatality\\r\\nfatally\\r\\nfatigue\\r\\nfault\\r\\nfaulty\\r\\nfear\\r\\nfeared\\r\\nfearful\\r\\nfearfulness\\r\\nfearing\\r\\nfearsome\\r\\nfeeble\\r\\nfelony\\r\\nfeud\\r\\nffs\\r\\nfight\\r\\nfighting\\r\\nfights\\r\\nfire\\r\\nfired\\r\\nfiring\\r\\nflirted\\r\\nflop\\r\\nflunk\\r\\nfoe\\r\\nfool\\r\\nfooling\\r\\nfoolish\\r\\nfoolishness\\r\\nfools\\r\\nforbid\\r\\nforbidden\\r\\nforbids\\r\\nforced\\r\\nforget\\r\\nforgotten\\r\\nfought\\r\\nfrantic\\r\\nfrantically\\r\\nfraud\\r\\nfrauds\\r\\nfraudulence\\r\\nfraudulent\\r\\nfreak\\r\\nfreaked\\r\\nfreaking\\r\\nfreakish\\r\\nfreakishly\\r\\nfreaks\\r\\nfreaky\\r\\nfreeload\\r\\nfreeloader\\r\\nfrenzy\\r\\nfriendless\\r\\nfrighten\\r\\nfrighteningly\\r\\nfrustrate\\r\\nfrustrated\\r\\nfrustrates\\r\\nfrustrating\\r\\nfrustratingly\\r\\nfrustration\\r\\nfuck\\r\\nfucked\\r\\nfucker\\r\\nfuckface\\r\\nfuckhead\\r\\nfucktard\\r\\nfuked\\r\\nfuking\\r\\nfumed\\r\\nfuneral\\r\\nfunky\\r\\nfurious\\r\\nfuriously\\r\\nfury\\r\\nfutile\\r\\ngag\\r\\ngeek\\r\\ngeeks\\r\\nghost\\r\\ngiddy\\r\\ngloomy\\r\\ngoddamn\\r\\ngoddamned\\r\\ngossip\\r\\ngossipy\\r\\ngrave\\r\\ngraveyard\\r\\ngreed\\r\\ngreedily\\r\\ngreedy\\r\\ngrief\\r\\ngrievance\\r\\ngrieve\\r\\ngrim\\r\\ngrimace\\r\\ngrimy\\r\\ngross\\r\\ngrossing\\r\\ngrossly\\r\\ngrrr\\r\\nguilt\\r\\nguilty\\r\\ngullibility\\r\\ngullible\\r\\ngun\\r\\nh7\\r\\nhapless\\r\\nharass\\r\\nharassed\\r\\nharasser\\r\\nharasses\\r\\nharassing\\r\\nharassment\\r\\nhard\\r\\nhardship\\r\\nharm\\r\\nharmfully\\r\\nharming\\r\\nharsh\\r\\nhate\\r\\nhated\\r\\nhateful\\r\\nhatefully\\r\\nhater\\r\\nhating\\r\\nhatred\\r\\nhaunt\\r\\nhavoc\\r\\nheartbreak\\r\\nheartbreaking\\r\\nheartbroken\\r\\nheartless\\r\\nheh\\r\\nhell\\r\\nhelpless\\r\\nhelplessness\\r\\nheroin\\r\\nhesitant\\r\\nhesitate\\r\\nhesitation\\r\\nhid\\r\\nhide\\r\\nhiding\\r\\nhindrance\\r\\nhoax\\r\\nhopeless\\r\\nhopelessly\\r\\nhorrendous\\r\\nhorrendously\\r\\nhorrible\\r\\nhorribleness\\r\\nhorribly\\r\\nhorrid\\r\\nhorrific\\r\\nhorrifically\\r\\nhorrify\\r\\nhorror\\r\\nhostile\\r\\nhostilities\\r\\nhostility\\r\\nhumiliate\\r\\nhumiliated\\r\\nhumiliates\\r\\nhumiliation\\r\\nhumorless\\r\\nhunger\\r\\nhurt\\r\\nhurtful\\r\\nhurting\\r\\nhypocritical\\r\\nhysteria\\r\\nidiot\\r\\nidiotic\\r\\nignoramus\\r\\nignoramuses\\r\\nignorance\\r\\nignorant\\r\\nignorantly\\r\\nignore\\r\\nignored\\r\\nignores\\r\\nignoring\\r\\nill\\r\\nillegal\\r\\nilliteracy\\r\\nillness\\r\\nillnesses\\r\\nimbecile\\r\\nimmoral\\r\\nimmorality\\r\\nimpatient\\r\\nimperfect\\r\\nimpoliteness\\r\\nimpose\\r\\nimposes\\r\\nimpotent\\r\\nimprisoned\\r\\ninability\\r\\ninaction\\r\\ninadequacy\\r\\ninadequate\\r\\nincapable\\r\\nincompetence\\r\\nincompetent\\r\\ninconsiderate\\r\\nindecisive\\r\\nindifferent\\r\\nindignant\\r\\nindoctrinate\\r\\nindoctrinated\\r\\nineffective\\r\\ninfected\\r\\ninferior\\r\\ninferiority\\r\\ninfringement\\r\\ninfuriate\\r\\ninjured\\r\\ninjury\\r\\ninjustice\\r\\ninquisition\\r\\ninsane\\r\\ninsanity\\r\\ninsecure\\r\\ninsecurity\\r\\ninsensitive\\r\\ninsignificant\\r\\ninsincere\\r\\ninsipid\\r\\ninsult\\r\\ninsulted\\r\\ninsulting\\r\\ninsults\\r\\ninterrupt\\r\\nintimidate\\r\\nintimidated\\r\\nintimidating\\r\\nintimidation\\r\\nirate\\r\\nironic\\r\\nirony\\r\\nirrational\\r\\nirrationally\\r\\nirresponsible\\r\\nirritant\\r\\nirritate\\r\\nirritated\\r\\nirritates\\r\\nirritating\\r\\nirritation\\r\\nisolate\\r\\nisolated\\r\\nisolation\\r\\njackass\\r\\njailed\\r\\njealous\\r\\njealousy\\r\\njeopardy\\r\\njerk\\r\\njerks\\r\\njoyless\\r\\njumpy\\r\\nkill\\r\\nkilled\\r\\nkiller\\r\\nkilling\\r\\nlack\\r\\nlag\\r\\nlame\\r\\nlament\\r\\nlamer\\r\\nlames\\r\\nlawsuit\\r\\nlazy\\r\\nleak\\r\\nleaked\\r\\nleave\\r\\nliability\\r\\nliar\\r\\nliars\\r\\nlibertine\\r\\nlied\\r\\nlimitation\\r\\nlimited\\r\\nlitigious\\r\\nlivid\\r\\nloathe\\r\\nlone\\r\\nloneliness\\r\\nlonely\\r\\nloner\\r\\nlonesome\\r\\nloose\\r\\nlose\\r\\nloser\\r\\nlosing\\r\\nloss\\r\\nlost\\r\\nlousy\\r\\nlow\\r\\nlower\\r\\nlowered\\r\\nlowest\\r\\nlowlife\\r\\nludicrous\\r\\nlunatic\\r\\nlurk\\r\\nlurking\\r\\nlying\\r\\nmad\\r\\nmadder\\r\\nmadness\\r\\nmaniac\\r\\nmaniacs\\r\\nmanipulated\\r\\nmanipulation\\r\\nmeaningless\\r\\nmediocrity\\r\\nmeh\\r\\nmelancholy\\r\\nmenace\\r\\nmess\\r\\nmessed\\r\\nmessy\\r\\nmia\\r\\nmindless\\r\\nmisbehave\\r\\nmischief\\r\\nmiserable\\r\\nmiserably\\r\\nmisery\\r\\nmisinformation\\r\\nmisleading\\r\\nmisread\\r\\nmiss\\r\\nmissed\\r\\nmistake\\r\\nmistaken\\r\\nmistakenly\\r\\nmisunderstand\\r\\nmisunderstanding\\r\\nmisunderstands\\r\\nmisunderstood\\r\\nmoan\\r\\nmoaning\\r\\nmock\\r\\nmocked\\r\\nmockery\\r\\nmocking\\r\\nmofo\\r\\nmolest\\r\\nmolestation\\r\\nmolested\\r\\nmolester\\r\\nmongering\\r\\nmonopolize\\r\\nmooch\\r\\nmoron\\r\\nmoronic\\r\\nmoronity\\r\\nmotherfucker\\r\\nmotherfucking\\r\\nmourn\\r\\nmourner\\r\\nmurder\\r\\nmurdered\\r\\nmurderer\\r\\nmurdering\\r\\nmurderous\\r\\nn00b\\r\\nnag\\r\\nnagger\\r\\nnaive\\r\\nnastier\\r\\nnastiness\\r\\nnasty\\r\\nneedy\\r\\nnegative\\r\\nnegativity\\r\\nneglect\\r\\nnerd\\r\\nnerdier\\r\\nnerdy\\r\\nnervous\\r\\nneurotic\\r\\nniggas\\r\\nnigger\\r\\nno\\r\\nnoisy\\r\\nnonsense\\r\\nnoob\\r\\nnotorious\\r\\nnumb\\r\\nnumbed\\r\\nnumbing\\r\\nnumbingly\\r\\nnuts\\r\\nobliterate\\r\\nobnoxious\\r\\nobscene\\r\\nobsess\\r\\nobsessed\\r\\nobsession\\r\\nobsessive\\r\\nobsolete\\r\\nobstacle\\r\\nodd\\r\\noffence\\r\\noffend\\r\\noffended\\r\\noffender\\r\\noffends\\r\\noffense\\r\\noffensive\\r\\noffensively\\r\\noppressed\\r\\noppressive\\r\\noutcry\\r\\noutrage\\r\\noutrageous\\r\\noverload\\r\\noverreact\\r\\noverreaction\\r\\noverweight\\r\\noverwhelm\\r\\noverwhelmingly\\r\\npain\\r\\npainful\\r\\npainfully\\r\\npanic\\r\\nparanoia\\r\\nparanoid\\r\\npassively\\r\\npathetic\\r\\npathetically\\r\\npeculiarly\\r\\npenalty\\r\\nperpetrator\\r\\npersecute\\r\\npersecuted\\r\\npersecutes\\r\\nperturbed\\r\\nperverse\\r\\nperversion\\r\\npervert\\r\\nperverted\\r\\npesky\\r\\npessimist\\r\\npetrify\\r\\npetty\\r\\nphobia\\r\\nphobic\\r\\npileup\\r\\npiss\\r\\npissants\\r\\npissed\\r\\npiteous\\r\\npitiable\\r\\npitiful\\r\\npity\\r\\npoison\\r\\npoisoning\\r\\npoisonous\\r\\npollute\\r\\npolluter\\r\\npoor\\r\\npoorer\\r\\npoverty\\r\\npowerless\\r\\nprejudice\\r\\nprejudiced\\r\\npressure\\r\\npressured\\r\\npretend\\r\\nprick\\r\\nprison\\r\\nprisoner\\r\\nproblem\\r\\nproblematic\\r\\npromiscuous\\r\\npropaganda\\r\\nprotest\\r\\nprotesting\\r\\nprovoke\\r\\nprovoked\\r\\nprovoking\\r\\npuke\\r\\npunish\\r\\npunishable\\r\\npunished\\r\\npunishes\\r\\npunishment\\r\\npunitive\\r\\npushy\\r\\nracism\\r\\nracist\\r\\nracists\\r\\nrage\\r\\nrancid\\r\\nrant\\r\\nrape\\r\\nraped\\r\\nraper\\r\\nraping\\r\\nrapist\\r\\nrapists\\r\\nrash\\r\\nrebel\\r\\nrebellion\\r\\nrebellious\\r\\nrecession\\r\\nreckless\\r\\nreek\\r\\nrefuse\\r\\nrefused\\r\\nregret\\r\\nregrettably\\r\\nregretted\\r\\nreject\\r\\nrejection\\r\\nreluctance\\r\\nreluctant\\r\\nreluctantly\\r\\nremorse\\r\\nrepetitive\\r\\nrepress\\r\\nrepression\\r\\nrepressive\\r\\nrepulse\\r\\nresent\\r\\nresentful\\r\\nresentment\\r\\nresents\\r\\nresign\\r\\nresignation\\r\\nresigns\\r\\nrestrict\\r\\nrestricted\\r\\nrestriction\\r\\nretard\\r\\nretarded\\r\\nrevenge\\r\\nridicule\\r\\nridiculous\\r\\nridiculously\\r\\nridiculousness\\r\\nrig\\r\\nrigged\\r\\nrigid\\r\\nriot\\r\\nriots\\r\\nrisk\\r\\nrisky\\r\\nrob\\r\\nrobber\\r\\nrobs\\r\\nrotten\\r\\nrude\\r\\nrudeness\\r\\nruin\\r\\nruined\\r\\nruiner\\r\\nsabotage\\r\\nsad\\r\\nsadden\\r\\nsaddened\\r\\nsadder\\r\\nsadly\\r\\nsarcasm\\r\\nsarcasms\\r\\nsarcastic\\r\\nsarcastically\\r\\nsavage\\r\\nsavagely\\r\\nsavagery\\r\\nscam\\r\\nscandal\\r\\nscandalous\\r\\nscapegoat\\r\\nscare\\r\\nscared\\r\\nscary\\r\\nscold\\r\\nscorn\\r\\nscream\\r\\nscreamed\\r\\nscreams\\r\\nscrew\\r\\nscrewing\\r\\nscumbag\\r\\nsedition\\r\\nseditious\\r\\nselfish\\r\\nselfishness\\r\\nserious\\r\\nseriously\\r\\nseriousness\\r\\nsevere\\r\\nsevered\\r\\nseverely\\r\\nshake\\r\\nshakedown\\r\\nshame\\r\\nshamed\\r\\nshameful\\r\\nshamefully\\r\\nshameless\\r\\nshamelessly\\r\\nshamelessness\\r\\nshit\\r\\nshithead\\r\\nshittiest\\r\\nshitting\\r\\nshitty\\r\\nshock\\r\\nshocked\\r\\nshocker\\r\\nshocking\\r\\nshockingly\\r\\nshook\\r\\nshoot\\r\\nshortage\\r\\nshy\\r\\nshyly\\r\\nshyness\\r\\nshyster\\r\\nsick\\r\\nsicken\\r\\nsickening\\r\\nsickens\\r\\nsilencing\\r\\nsilliness\\r\\nsin\\r\\nsinful\\r\\nsinister\\r\\nskeptic\\r\\nskeptical\\r\\nskepticism\\r\\nslam\\r\\nslash\\r\\nslavery\\r\\nslut\\r\\nsluts\\r\\nslutty\\r\\nsmear\\r\\nsmh\\r\\nsneaky\\r\\nsnob\\r\\nsnobbery\\r\\nsnobbish\\r\\nsnobby\\r\\nsnobs\\r\\nsnub\\r\\nsob\\r\\nsore\\r\\nsorrow\\r\\nsorry\\r\\nspam\\r\\nspamming\\r\\nspite\\r\\nspiteful\\r\\nstab\\r\\nstabbed\\r\\nstall\\r\\nstank\\r\\nstartle\\r\\nstarve\\r\\nsteal\\r\\nstealer\\r\\nstealing\\r\\nstench\\r\\nstereotype\\r\\nstereotyped\\r\\nstingy\\r\\nstink\\r\\nstinky\\r\\nstolen\\r\\nstop\\r\\nstopped\\r\\nstops\\r\\nstrain\\r\\nstrange\\r\\nstrangely\\r\\nstress\\r\\nstressed\\r\\nstressful\\r\\nstrike\\r\\nstruck\\r\\nstruggle\\r\\nstubborn\\r\\nstuck\\r\\nstunk\\r\\nstupid\\r\\nstupider\\r\\nstupidity\\r\\nstupidly\\r\\nstupidness\\r\\nstutter\\r\\nstutterer\\r\\nstuttering\\r\\nsubmissive\\r\\nsubversive\\r\\nsuck\\r\\nsucked\\r\\nsucker\\r\\nsuckered\\r\\nsuffer\\r\\nsuffered\\r\\nsufferer\\r\\nsuffering\\r\\nsuffers\\r\\nsuicidal\\r\\nsuicide\\r\\nsuing\\r\\nsuspect\\r\\nsuspected\\r\\nsuspend\\r\\nsuspended\\r\\nsuspicion\\r\\nsuspicious\\r\\nsux\\r\\nswear\\r\\ntalentless\\r\\ntantrum\\r\\ntard\\r\\ntears\\r\\ntease\\r\\nteased\\r\\nteaser\\r\\ntemper\\r\\ntense\\r\\ntension\\r\\nterrible\\r\\nterribly\\r\\nterrified\\r\\nterrify\\r\\nterrifying\\r\\nterror\\r\\nterrorise\\r\\nterrorises\\r\\nterrorism\\r\\nterrorisms\\r\\nterrorist\\r\\nterroristic\\r\\nterrorists\\r\\nterrorize\\r\\nterrorized\\r\\nthief\\r\\nthieve\\r\\nthoughtless\\r\\nthreat\\r\\nthreaten\\r\\nthreatened\\r\\nthreatening\\r\\nthreatens\\r\\nthreating\\r\\nthreats\\r\\ntimid\\r\\ntired\\r\\ntoothless\\r\\ntorn\\r\\ntorture\\r\\ntortured\\r\\ntorturous\\r\\ntotalitarian\\r\\ntotalitarianism\\r\\ntough\\r\\ntoughest\\r\\ntoughness\\r\\ntout\\r\\ntragedy\\r\\ntragic\\r\\ntragically\\r\\ntrap\\r\\ntrauma\\r\\ntraumas\\r\\ntraumatic\\r\\ntraumatise\\r\\ntraumatize\\r\\ntraumatized\\r\\ntraumatizing\\r\\ntravesty\\r\\ntreason\\r\\ntreasonous\\r\\ntrick\\r\\ntricked\\r\\ntrickster\\r\\ntricky\\r\\ntrivialise\\r\\ntrivialises\\r\\ntrouble\\r\\ntroubled\\r\\ntroublemaker\\r\\ntroublesome\\r\\ntwat\\r\\nugliest\\r\\nugliness\\r\\nugly\\r\\nunacceptable\\r\\nunappreciated\\r\\nunattractive\\r\\nunaware\\r\\nuncertain\\r\\nuncertainty\\r\\nunclear\\r\\nuncomfortable\\r\\nunconfirmed\\r\\nuncontrollable\\r\\nuncontrollably\\r\\nuncredited\\r\\nunderestimate\\r\\nunderestimated\\r\\nundermine\\r\\nundermines\\r\\nundermining\\r\\nundeserving\\r\\nundesirable\\r\\nunease\\r\\nunemployment\\r\\nunequal\\r\\nunethical\\r\\nunfair\\r\\nunfortunate\\r\\nunfortunately\\r\\nungrateful\\r\\nunhappy\\r\\nunhealthy\\r\\nunimportant\\r\\nunimpressed\\r\\nunimpressive\\r\\nunintelligent\\r\\nunjust\\r\\nunloved\\r\\nunmatched\\r\\nunpleasant\\r\\nunprofessional\\r\\nunprotected\\r\\nunsophisticated\\r\\nunstable\\r\\nunsuccessful\\r\\nunsupported\\r\\nunsure\\r\\nunwanted\\r\\nunworthy\\r\\nupset\\r\\nupsetting\\r\\nuptight\\r\\nuseless\\r\\nvague\\r\\nvain\\r\\nvanity\\r\\nvicious\\r\\nviciously\\r\\nviciousness\\r\\nvictim\\r\\nvictimhood\\r\\nvictimise\\r\\nvictimization\\r\\nvictimize\\r\\nvictimized\\r\\nvictimizes\\r\\nvile\\r\\nvillain\\r\\nvillains\\r\\nviolate\\r\\nviolated\\r\\nviolater\\r\\nviolation\\r\\nviolator\\r\\nviolence\\r\\nviolent\\r\\nviolently\\r\\nvirulent\\r\\nvulnerability\\r\\nvulnerable\\r\\nvulture\\r\\nwag\\r\\nwanker\\r\\nwar\\r\\nwarfare\\r\\nwarmongering\\r\\nwarn\\r\\nwarning\\r\\nwaste\\r\\nwasted\\r\\nwasting\\r\\nweak\\r\\nweaken\\r\\nweaker\\r\\nweakling\\r\\nweakly\\r\\nweakness\\r\\nweaknesses\\r\\nweapon\\r\\nweary\\r\\nweep\\r\\nweepy\\r\\nweird\\r\\nweirder\\r\\nweirdly\\r\\nweirdness\\r\\nweirdo\\r\\nweirdos\\r\\nwept\\r\\nwhine\\r\\nwhiner\\r\\nwhining\\r\\nwhore\\r\\nwhoredom\\r\\nwicked\\r\\nwickedly\\r\\nwickedness\\r\\nwimp\\r\\nwimpiest\\r\\nwimps\\r\\nwimpy\\r\\nwitch\\r\\nwoe\\r\\nwoeful\\r\\nworn\\r\\nworried\\r\\nworrisome\\r\\nworry\\r\\nworse\\r\\nworst\\r\\nworthless\\r\\nwreck\\r\\nwrong\\r\\nwtf\\r\\nwth\\r\\nyucky\\r\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to load the corpus\n",
    "\n",
    "import nltk.data\n",
    "nltk.data.load('nltk_data/corpora/dataset/AbusiveWords-ver1.txt', format='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f6e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus.reader import WordListCorpusReader\n",
    "\n",
    "\n",
    "w = WordListCorpusReader('.', ['nltk_data\\\\corpora\\\\dataset\\\\AbusiveWords-ver1.txt'])\n",
    "wordList = w.words()\n",
    "\n",
    "wordString = \" \"\n",
    "\n",
    "wordString = wordString.join(wordList)\n",
    "\n",
    "# convert all words to capitalize letters\n",
    "\n",
    "caps = wordString.title()\n",
    "caps_list = list(caps.split(\" \"))\n",
    "\n",
    "#copy all capitalize words into a txt file\n",
    "with open(r'capsList.txt', 'w') as fp:\n",
    "    # write each item on a new line\n",
    "    for item in caps_list:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "    \n",
    "\n",
    "# convert all words to uppercase letters\n",
    "\n",
    "upper = wordString.upper()\n",
    "upper_list = list(upper.split(\" \"))\n",
    "\n",
    "#copy all uppercase words into a txt file\n",
    "with open(r'upperList.txt', 'w') as fp:\n",
    "    # write each item on a new line\n",
    "    for item in upper_list:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71815798",
   "metadata": {},
   "source": [
    "All the files (capsList.txt, upperList.txt, AbusiveWords-ver1) are combined to produced the final version of list of abusive words called AbusiveWords (final).txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
